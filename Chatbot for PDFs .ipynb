{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfMuITSUiJYE"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit\n",
        "!pip install pyngrok\n",
        "\n",
        "!ngrok authtoken 2ZaukEX2dpEdTGQatDve7dPpmGL_3u8Eur4MtR4aXCYparH96\n",
        "\n",
        "!ngrok\n",
        "\n",
        "!pip install langchain\n",
        "!pip install faiss-cpu\n",
        "!pip install faiss-gpu\n",
        "!pip install PyPDF2\n",
        "!pip install langchain sentence_transformers\n",
        "!pip install huggingface_hub\n",
        "!pip install transformers\n",
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile htmlTemplates.py\n",
        "\n",
        "\n",
        "user_template = '''\n",
        "    <div class=\"chat-message user\" style=\"padding: 0.5rem; border-radius: 2rem; margin-bottom: 0.25rem; display: flex;\">\n",
        "        <div class=\"avatar\">\n",
        "            <img src=\"https://th.bing.com/th/id/OIP.7G6XwS4BzQWHQl-VoyvCFgHaHa?rs=1&pid=ImgDetMain\" style=\"width: 60px; height: 60px;\">\n",
        "        </div>\n",
        "        <div class=\"message\" style=\"background-color: #FFFFFF;\">\n",
        "            {message}\n",
        "        </div>\n",
        "    </div>\n",
        "    '''\n",
        "\n",
        "bot_template = '''\n",
        "    <div class=\"chat-message bot\" style=\"padding: 1rem; border-radius: 2rem; margin-bottom: 0.25rem; display: flex;\">\n",
        "        <div class=\"avatar\">\n",
        "            <img src=\"https://th.bing.com/th/id/OIP.j21DfVny1Hush30Nvo-oGAHaHa?rs=1&pid=ImgDetMain\" style=\"width: 60px; height: 60px;\">\n",
        "        </div>\n",
        "        <div class=\"message\" style=\"background-color: #FFFFFF;\">\n",
        "            {message}\n",
        "        </div>\n",
        "    </div>\n",
        "    '''"
      ],
      "metadata": {
        "id": "WszQAbw4rJqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import langchain\n",
        "import PyPDF2\n",
        "import transformers\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "import os\n",
        "from langchain.llms import HuggingFaceHub, OpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from htmlTemplates import bot_template, user_template\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = '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'\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
        "\n",
        "\n",
        "\n",
        "def get_raw_text(pdf_docs):\n",
        "    text = ''\n",
        "    for pdf in pdf_docs:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf)\n",
        "        for pages in pdf_reader.pages:\n",
        "            text += pages.extract_text()\n",
        "    st.write(\"Raw text extracted\")\n",
        "    return text\n",
        "\n",
        "\n",
        "def get_text_chunks(text):\n",
        "    text_splliter = CharacterTextSplitter(\n",
        "        separator='\\n',\n",
        "        chunk_size=800,\n",
        "        chunk_overlap=20,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text_splliter.split_text(text)\n",
        "    st.write(\"Chunks splited\")\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def get_vectorestore(text_chunks):\n",
        "    embeddings = HuggingFaceEmbeddings()\n",
        "    vectorestore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
        "    st.write(\"Stored to Vectorestore\")\n",
        "    return vectorestore\n",
        "\n",
        "\n",
        "def get_conversation(vectorstore):\n",
        "\n",
        "\n",
        "    #repo_id = \"tiiuae/falcon-7b-instruct\"\n",
        "    repo_id = \"google/flan-t5-xxl\"\n",
        "\n",
        "    llm = HuggingFaceHub(\n",
        "        repo_id=repo_id, model_kwargs={\"temperature\": 0.1, \"max_length\": 500}\n",
        "    )\n",
        "\n",
        "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        memory=memory,\n",
        "        retriever=vectorstore.as_retriever()\n",
        "    )\n",
        "    return conversation_chain\n",
        "\n",
        "\n",
        "def handle_user_input(user_question):\n",
        "    response = st.session_state.conversation({'question':user_question})\n",
        "    st.session_state.chat_history = response['chat_history']\n",
        "\n",
        "    for i, message in enumerate(st.session_state.chat_history):\n",
        "        if i%2==0:\n",
        "            st.write(user_template.replace(\"{message}\", message.content), unsafe_allow_html=True)\n",
        "\n",
        "        else:\n",
        "            st.write(bot_template.replace(\"{message}\", message.content), unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "st.set_page_config(page_title='Chat with your PDFs', page_icon=\":books:\")\n",
        "\n",
        "if 'conversation' not in st.session_state:\n",
        "    st.session_state.conversation=None\n",
        "\n",
        "\n",
        "st.header('Chat with your PDFs :books:')\n",
        "user_question = st.text_input('Enter your query here')\n",
        "\n",
        "if user_question:\n",
        "    handle_user_input(user_question)\n",
        "\n",
        "with st.sidebar:\n",
        "    st.subheader('Your Documents')\n",
        "    pdf_docs = st.file_uploader('Upload your files here and press \"Process\"', accept_multiple_files=True)\n",
        "    if st.button('Process'):\n",
        "        with st.spinner('Processing'):\n",
        "          raw_text = get_raw_text(pdf_docs)\n",
        "\n",
        "          #breaking the text into text chunks\n",
        "          text_chunks = get_text_chunks(raw_text)\n",
        "\n",
        "          #converting the chunks into embeddings and storing them in vector database\n",
        "          vectorstore = get_vectorestore(text_chunks)\n",
        "\n",
        "          #creating conversational chatbot\n",
        "          st.session_state.conversation = get_conversation(vectorstore)\n",
        "          st.write(\"Process Completed\")"
      ],
      "metadata": {
        "id": "Nz2M8B4okA8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "oDTHGtVHnEsb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pgrep streamlit"
      ],
      "metadata": {
        "id": "yjPFpeT8ttQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "# Setup a tunnel to the streamlit port 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "public_url"
      ],
      "metadata": {
        "id": "XUJdeYlAniFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6V5lZeB0pk_1"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}
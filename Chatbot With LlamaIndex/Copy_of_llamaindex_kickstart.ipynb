{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Get started with LlamaIndex"
      ],
      "metadata": {
        "id": "1WwQq5nR7nH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index langchain pypdf\n",
        "!pip install -U langchain-community\n",
        "!pip install llama_index.llms.huggingface\n",
        "!pip install sentence-transformers\n",
        "!pip install llama-index-embeddings-langchain\n",
        "!pip install llama-index-llms-gemini"
      ],
      "metadata": {
        "id": "4eygJbkj6qH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, get_response_synthesizer, SummaryIndex\n",
        "from llama_index.core import ServiceContext, StorageContext,load_index_from_storage, PromptHelper\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "#from llama_index.embeddings import LangchainEmbedding\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "#from llama_index.llms import HuggingFaceInferenceAPI\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.llms.huggingface.base import HuggingFaceInferenceAPI\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "import os\n",
        "#from llama_index.llms.anthropic import Anthropic\n",
        "from llama_index.core import Settings"
      ],
      "metadata": {
        "id": "3Hi13ZrCm03b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Environment variables"
      ],
      "metadata": {
        "id": "RdWj26KmD-q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyCKnwTG-kvt2B6vH0OBMRdUhhsP3lZHGic'\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = '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'\n",
        "os.environ['ANTHROPIC_API_KEY'] = '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'\n",
        "os.environ['LLAMA_CLOUD_API_KEY'] = 'llx-ZkhJIBo5MR8XoVo6RnJvaQdtUySysluPWivHopC088TTID54'"
      ],
      "metadata": {
        "id": "XDDrL5MDEFuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create parser and parse document into nodes"
      ],
      "metadata": {
        "id": "rKhzlFP0nxE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PERSIST_DIR = \"./storage\"\n",
        "embed_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-large\")\n",
        "llm = Gemini(model=\"models/gemini-1.0-pro\", temperature=0.9)\n",
        "\n",
        "\n",
        "if not os.path.exists(PERSIST_DIR):\n",
        "    documents = SimpleDirectoryReader(\"/content/data\").load_data()\n",
        "    parser = SimpleNodeParser()\n",
        "    nodes = parser.get_nodes_from_documents(documents)\n",
        "    '''\n",
        "    llm = HuggingFaceInferenceAPI(\n",
        "        model_name=\"google/flan-t5-xxl\", token=HF_TOKEN\n",
        "    )\n",
        "    '''\n",
        "\n",
        "    llm = Gemini(model=\"models/gemini-1.0-pro\", temperature=0.9)\n",
        "    #llm2 = Anthropic(model='claude-3-sonnet-20240229')\n",
        "\n",
        "    prompt_helper = PromptHelper(\n",
        "        context_window=500,\n",
        "        #num_output=256,\n",
        "        chunk_overlap_ratio=0.1,\n",
        "        #chunk_size_limit=512,\n",
        "    )\n",
        "\n",
        "    Settings.chunk_size = 600\n",
        "    service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm, prompt_helper=prompt_helper)  # chunk_size=512\n",
        "    storage_context = StorageContext.from_defaults() #vector store\n",
        "    index = VectorStoreIndex(\n",
        "        nodes,\n",
        "        service_context=service_context,\n",
        "        storage_context=storage_context,\n",
        "    )\n",
        "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
        "\n",
        "else:\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
        "    index = load_index_from_storage(storage_context, embed_model=embed_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "MorKNRXopKDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = VectorIndexRetriever(\n",
        "    index=index,\n",
        "    similarity_top_k = 30\n",
        ")\n"
      ],
      "metadata": {
        "id": "RYZwk2aEAW_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#llm = Gemini(model=\"models/gemini-1.0-pro\", temperature=0.9)\n",
        "response_synthesizer = get_response_synthesizer(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    streaming=True,\n",
        "    llm = llm\n",
        ")"
      ],
      "metadata": {
        "id": "ZSgKdZILb5v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#query_engine = index.as_query_engine()\n",
        "\n",
        "query_engine = RetrieverQueryEngine(\n",
        "    retriever=retriever,\n",
        "    response_synthesizer=response_synthesizer,\n",
        "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)]\n",
        ")"
      ],
      "metadata": {
        "id": "L11VipyZq8QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is policy optimization algorithm?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "_3vp8Fl3d8vU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "83f5999b-4102-4628-a0cb-a47e13db132b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Policy optimization algorithms are a class of reinforcement learning algorithms that directly optimize a parametrized policy function to maximize a given objective function. They typically use gradient-based methods to iteratively update the policy parameters based on the estimated gradient of the objective function with respect to the policy parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chat engine"
      ],
      "metadata": {
        "id": "hZfJiP-hkqRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_engine = index.as_chat_engine()\n",
        "response_2 = chat_engine.chat(\"What is reinforcement learning?\")"
      ],
      "metadata": {
        "id": "8kBCV1M0I3gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_2)"
      ],
      "metadata": {
        "id": "wu8wiuDCkyO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91db6bb7-47b2-4dab-a746-04fa41e34a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinforcement learning is a type of machine learning in which an agent learns to take actions in an environment to maximize its reward. The agent interacts with the environment, receives feedback in the form of rewards, and learns to adjust its actions to increase its rewards over time. Reinforcement learning is different from supervised learning, which uses labeled data to learn, and unsupervised learning, which finds structure in unlabeled data. Reinforcement learning is based on the idea of Markov decision processes, which are mathematical models of environments that can be used to optimize the agent's behavior.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vhEHPCtLk6sX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
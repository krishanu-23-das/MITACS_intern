{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Get started with LlamaIndex"
      ],
      "metadata": {
        "id": "1WwQq5nR7nH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index langchain pypdf\n",
        "!pip install -U langchain-community\n",
        "!pip install llama_index.llms.huggingface\n",
        "!pip install sentence-transformers\n",
        "!pip install llama-index-embeddings-langchain\n",
        "!pip install llama-index-llms-gemini"
      ],
      "metadata": {
        "id": "4eygJbkj6qH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"
      ],
      "metadata": {
        "id": "WztYMt1chvsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import ServiceContext, StorageContext,load_index_from_storage, PromptHelper\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "#from llama_index.embeddings import LangchainEmbedding\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "#from llama_index.llms import HuggingFaceInferenceAPI\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.llms.huggingface.base import HuggingFaceInferenceAPI\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine"
      ],
      "metadata": {
        "id": "3Hi13ZrCm03b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create parser and parse document into nodes"
      ],
      "metadata": {
        "id": "rKhzlFP0nxE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "6G_cIKCHpAGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PERSIST_DIR = \"./storage\"\n",
        "\n",
        "#if not os.path.exists(PERSIST_DIR):\n",
        "documents = SimpleDirectoryReader(\"/content/data\").load_data()\n",
        "parser = SimpleNodeParser()\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "'''\n",
        "llm = HuggingFaceInferenceAPI(\n",
        "    model_name=\"google/flan-t5-xxl\", token=HF_TOKEN\n",
        ")\n",
        "'''\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyCKnwTG-kvt2B6vH0OBMRdUhhsP3lZHGic'\n",
        "\n",
        "\n",
        "llm = Gemini(model=\"models/gemini-1.0-pro\", temperature=0.9)\n",
        "embed_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-large\")\n",
        "\n",
        "prompt_helper = PromptHelper(\n",
        "    context_window=500,\n",
        "    #num_output=256,\n",
        "    chunk_overlap_ratio=0.1,\n",
        "    chunk_size_limit=None,\n",
        ")\n",
        "\n",
        "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm, chunk_size=512, prompt_helper=prompt_helper)\n",
        "storage_context = StorageContext.from_defaults() #vector store\n",
        "index = VectorStoreIndex(\n",
        "    nodes,\n",
        "    service_context=service_context,\n",
        "    storage_context=storage_context,\n",
        ")\n",
        "index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
        "'''\n",
        "else:\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
        "    index = load_index_from_storage(storage_context)\n",
        "'''"
      ],
      "metadata": {
        "id": "MorKNRXopKDt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "f4d1e546-2256-426c-db7c-1ee80c419d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "<ipython-input-75-6063c58be8eb>:26: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm, chunk_size=512, prompt_helper=prompt_helper)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nelse:\\n    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\\n    index = load_index_from_storage(storage_context)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = VectorIndexRetriever(\n",
        "    index=index,\n",
        "    similarity_top_k=10,\n",
        ")"
      ],
      "metadata": {
        "id": "RYZwk2aEAW_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuaiVApIniDg",
        "outputId": "4118aa09-3ff3-40fd-eca7-26a63f57bf79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2856"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nodes[99].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGCubIdx7JxD",
        "outputId": "b64bcb8f-d1c1-4e28-842b-8f54517ebcbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1643"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#query_engine = index.as_query_engine()\n",
        "\n",
        "query_engine = RetrieverQueryEngine(\n",
        "    retriever=retriever,\n",
        ")\n",
        "response = query_engine.query(\"who was Chani?\")"
      ],
      "metadata": {
        "id": "L11VipyZq8QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "Nv7BCbgJGoQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apaaXNJCrE6L",
        "outputId": "8602ca30-1ee3-47d0-9d08-ffc8dd73f487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chani is the daughter of Liet and is a Fremen. She is also a Sayyadina, which is a consecrated woman in the Fremen culture.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(response.source_nodes[2].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW1aaIdQGIoU",
        "outputId": "8ce14adc-1f75-4575-cec9-f7e0b36b8cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2215"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.source_nodes[2].text)"
      ],
      "metadata": {
        "id": "Mc0T0pwxoPT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "EtbJ3PQgks3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_2 = query_engine.query(\"How Stilgar dies?\")"
      ],
      "metadata": {
        "id": "J5mLWOc5l3qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_TY5fqfm4V8",
        "outputId": "354855d8-021a-4067-e035-686dbcaf9bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This context does not mention anything about Stilgar's death, so I cannot answer this question from the provided context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_2"
      ],
      "metadata": {
        "id": "6PhPPaq5BJ2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8kBCV1M0I3gp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}